import { Token, MatchPrefix } from './tokens';
/**
 * The lexer turns input into a list of tokens.
 */
export declare class Lexer implements IterableIterator<Token> {
    private input;
    private quotes;
    private position;
    /**
     * @param input - Input string.
     */
    constructor(input?: string);
    /**
     * Sets the input to use.
     * This will reset the lexer.
     * @param input - Input to use.
     * @returns The lexer.
     */
    setInput(input: string): this;
    /**
     * Sets the quotes to use.
     * This can be done in the middle of lexing.
     *
     * ```ts
     * const lexer = new Lexer('"hello"');
     * lexer.setQuotes([['"', '"']]);
     * const xs = lexer.lex();
     * console.log(xs);
     * >>> [{ value: 'hello', raw: '"hello"', trailing: '' }]
     * ```
     *
     * @param quotes - List of pairs of open and close quotes.
     * It is required that these strings do not contain any whitespace characters.
     * The matching of these quotes will be case-sensitive.
     * @returns The lexer.
     */
    setQuotes(quotes: [string, string][]): this;
    /**
     * Resets the position of the lexer.
     * @return The lexer.
     */
    reset(): this;
    /**
     * Whether the lexer is finished.
     */
    get finished(): boolean;
    private match;
    private matchR;
    private shift;
    /**
     * Gets the next token.
     * @returns An iterator result containing the next token.
     */
    next(): IteratorResult<Token>;
    private nextToken;
    private pWs;
    private pQuoted;
    private pWord;
    [Symbol.iterator](): this;
    /**
     * Runs the lexer.
     * This consumes the lexer.
     *
     * ```ts
     * const lexer = new Lexer('hello world');
     * const xs = lexer.lex();
     * console.log(xs);
     * >>> [
     *   { value: 'hello', raw: 'hello', trailing: ' ' },
     *   { value: 'world', raw: 'world', trailing: '' }
     * ]
     * ```
     *
     * @returns All the tokens lexed.
     */
    lex(): Token[];
    /**
     * Runs the lexer, matching a prefix and command.
     * This consumes at most two tokens of the lexer.
     * This uses {@linkcode extractCommand} under the hood.
     *
     * ```ts
     * const lexer = new Lexer('!help me');
     * const r = lexer.lexCommand(s => s.startsWith('!') ? 1 : null);
     * if (r != null) {
     *   const [command, getRest] = r;
     *   console.log(command.value);
     *   >>> 'help'
     *   console.log(getRest()[0].value);
     *   >>> 'me'
     * }
     * ```
     *
     * @param matchPrefix - A function that gives the length of the prefix if there is one.
     * @returns The command and the rest of the lexed tokens, as long as the prefix was matched.
     * The rest of the tokens are delayed as a function.
     */
    lexCommand(matchPrefix: MatchPrefix): [Token, () => Token[]] | null;
}
